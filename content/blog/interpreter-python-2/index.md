---
title: íŒŒì´ì¬ìœ¼ë¡œ ì¸í„°í”„ë¦¬í„° ë§Œë“¤ê¸° | 2 - Lexer êµ¬í˜„í•˜ê¸°
date: "2019-06-09T07:04:47Z"
---

![](python_interpreter_2.png)

ì´ ê¸€ì€ [velog](https://velog.io/@devonnuri/%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%9C%BC%EB%A1%9C-%EC%9D%B8%ED%84%B0%ED%94%84%EB%A6%AC%ED%84%B0-%EB%A7%8C%EB%93%A4%EA%B8%B0-2-Lexer-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0)ì—ë„ ê¸°ê³ ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

ë¬¸ë²•ë„ ì–´ëŠì •ë„ ê°–ì¶”ì–´ì¡Œìœ¼ë‹ˆ ì¸í„°í”„ë¦¬í„°ê°€ ì–´ë–»ê²Œ êµ¬ì„±ë˜ëŠ”ì§€ ì•Œì•„ë´…ì‹œë‹¤.

![lsbasi_part13_img03.png](https://images.velog.io/post-images/devonnuri/9edc2060-89d0-11e9-b489-01d6493e8bd1/lsbasipart13img03.png)

(ì´ë¯¸ì§€ ì¶œì²˜: [Letâ€™s Build A Simple Interpreter. Part 13: Semantic Analysis.](https://ruslanspivak.com/lsbasi-part13/))

ë¨¼ì € Lexerë¡œ ì†ŒìŠ¤ì½”ë“œë¥¼ í† í° ë‹¨ìœ„ë¡œ ë¶„ì„í•˜ê³ , Parserë¡œ ìš°ì„ ìˆœìœ„ì— ë§ì¶°ì„œ Abstract Syntax Treeë¥¼ ë§Œë“¤ì–´ì¤€ ë’¤, Semantic Analyzerë¡œ Type checking ê°™ì€ ì˜ë¯¸ ë¶„ì„ì„ í•˜ê³ , ìµœì¢…ì ìœ¼ë¡œ Interpreterê°€ ì—°ì‚°í•´ì„œ í”„ë¡œê·¸ë¨ì„ ì‹¤í–‰í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ê·¸ëŸ¼ ë¨¼ì €, Lexerë¥¼ ë§Œë“¤ì–´ë³´ë„ë¡ í•©ì‹œë‹¤.

# 0. ğŸšª ìš°ë¦¬ì˜ ëª©í‘œ

í† í°ì€ êµ­ì–´ì˜ í˜•íƒœì†Œì™€ ë¹„ìŠ·í•œ ê°œë…ì…ë‹ˆë‹¤. í˜•íƒœì†Œê°€ ë¬¸ì¥ì„ ì´ë£¨ëŠ” ì˜ë¯¸ë¥¼ ê°€ì§„ ê°€ì¥ ì‘ì€ ìš”ì†Œì¸ ê²ƒê³¼ ê°™ì´ í† í°ì€ ì˜ë¯¸ë¥¼ ê°€ì§€ëŠ” ê¸€ìë¼ë¦¬ ëª¨ì•„ë‘” ì†ŒìŠ¤ì½”ë“œë¥¼ ì´ë£¨ëŠ” ê°€ì¥ ì‘ì€ ìš”ì†Œì…ë‹ˆë‹¤. ì†ŒìŠ¤ì½”ë“œë¥¼ í† í°ìœ¼ë¡œ ìª¼ê°œì£¼ëŠ” ê²ƒì„ `Lexer`ë¼ê³  í•©ë‹ˆë‹¤.

ì´ë¥¼ í…Œë©´, ë‹¤ìŒê³¼ ê°™ì€ ì½”ë“œê°€ ìˆìŠµë‹ˆë‹¤.

```
10*2+3
```

ì´ ì½”ë“œë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ìª¼ê°¤ ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

```
NUMBER 10
STAR *
NUMBER 2
PLUS +
NUMBER 3
```

# 1. ğŸ¤” í† í° êµ¬ì„±

ì ê·¸ëŸ¼ ì–¸ì–´ì˜ í† í°ë“¤ì„ ìƒê°í•´ë´…ì‹œë‹¤.
í† í°ë“¤ì€ êµ¬í˜„í•  ë–„ë§ˆë‹¤ ì¶”ê°€ë  ì˜ˆì •ì´ì§€ë§Œ, í˜„ì¬ ì œê°€ êµ¬ìƒí•˜ê³  ìˆëŠ” í† í°ë“¤ì„ Python Enumìœ¼ë¡œ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

[rectapy/token/tokentype.py](https://github.com/devonnuri/RectaPy/blob/master/rectapy/token/tokentype.py)
```python
from enum import Enum, auto


class TokenType(Enum):
  LEFT_PAREN = auto() # (
  RIGHT_PAREN = auto() # )
  LEFT_BRACE = auto() # {
  RIGHT_BRACE = auto() # }
  LEFT_BRACKET = auto() # [
  RIGHT_BRACKET = auto() # ]
  SEMICOLON = auto() # ;

  COMMA = auto() # ,
  DOT = auto() # .
  PLUS = auto() # +
  MINUS = auto() # -
  STAR = auto() # *
  SLASH = auto() # /

  EQUAL = auto() # =
  EQUAL_EQUAL = auto() # ==
  EXCLAM = auto() # !
  EXCLAM_EQUAL = auto() # !=
  GREATER = auto() # >
  GREATER_EQUAL = auto() # >=
  LESS = auto() # <
  LESS_EQUAL = auto() # <=

  IDENTIFIER = auto() # Variable name, Function name, etc... ([a-zA-Z][a-zA-Z0-9]*)

  BOOLEAN = auto() # true, false
  NUMBER = auto() # Digit([0-9]+(.[0-9]*)?)
  SINGLE_STRING = auto() # 'string'
  DOUBLE_STRING = auto() # "string"

  EOF = auto() # End of file

  # Keywords
  IF = 'if'
  ELSE = 'else'
  AND = 'and'
  OR = 'or'
  FUN = 'fun'
  VAR = 'var'
  TRUE = 'true'
  FALSE = 'false'
  NULL = 'null'
  FOR = 'for'
  WHILE = 'while'
  IN = 'in'
  RETURN = 'return'

  @classmethod
  def has_value(cls, value):
    return any(value == item.value for item in cls)
```

ë§ˆì§€ë§‰ì— `has_value` ë©”ì„œë“œëŠ” Lexerë¥¼ êµ¬í˜„í• ë•Œ í‚¤ì›Œë“œë¥¼ ê°€ì ¸ì˜¬ë–„ ì‚¬ìš©ë©ë‹ˆë‹¤.

# 2. ğŸ“ Lexer ì‘ì„±

ì¼ë‹¨ Lexer í´ë˜ìŠ¤ë¥¼ ì‘ì„±í•´ì¤ë‹ˆë‹¤.

[rectapy/token/lexer.py](https://github.com/devonnuri/RectaPy/blob/95d855dd5c2a8607be0c32d4b70deeef4957fc66/rectapy/token/lexer.py#L9)
```python
class Lexer:
  def __init__(self, source: str):
    self.source = source    # ì†ŒìŠ¤ ì½”ë“œ
    self.tokens = []        # íŒŒì‹±ëœ í† í°
    self.start = 0			# í† í°ì˜ ì‹œì‘
    self.current = 0		# í† í°ì˜ ë
    self.line = 1			# ë¼ì¸
```

## 2.1 `scan_token` ë©”ì„œë“œ

í† í° í•˜ë‚˜ë¥¼ ë¶„ì„í•˜ëŠ” `scan_token` ë©”ì„œë“œë¥¼ ë§Œë“¤ì–´ë´…ì‹œë‹¤.

[rectapy/token/lexer.py](https://github.com/devonnuri/RectaPy/blob/95d855dd5c2a8607be0c32d4b70deeef4957fc66/rectapy/token/lexer.py#L25)
```python
def scan_token(self) -> None:
  ch = self.advance()

  if ch == '(':
    self.add_token(TokenType.LEFT_PAREN)
  elif ch == ')':
    self.add_token(TokenType.RIGHT_PAREN)
  elif ch == '{':
    self.add_token(TokenType.LEFT_BRACE)
  # ...
  elif ch == '!':
    self.add_token(TokenType.EXCLAM_EQUAL if self.match('=') else TokenType.EXCLAM)
  elif ch == '=':
    self.add_token(TokenType.EQUAL_EQUAL if self.match('=') else TokenType.EQUAL)
  elif ch == '<':
    self.add_token(TokenType.LESS_EQUAL if self.match('=') else TokenType.LESS)
  elif ch == '>':
    self.add_token(TokenType.GREATER_EQUAL if self.match('=') else TokenType.GREATER)
  elif ch == '/':
    if self.match('/'):
      while self.peek() != '\n' and not self.is_end():
        self.advance()
    else:
      self.add_token(TokenType.SLASH)
  elif ch.isspace():
    pass
  elif ch == '\n':
    self.line += 1
  elif ch == '"' or ch == '\'':
    while self.peek() != ch and not self.is_end():
    if self.peek() == '\n':
      self.line += 1
    self.advance()

    if self.is_end():
      raise InvalidSyntaxError('Unterminated string')

    self.advance()
    self.add_token(
      TokenType.DOUBLE_STRING if ch == '"' else TokenType.SINGLE_STRING,
      self.source[self.start: self.current].strip(ch)
    )
  elif Lexer.is_digit(ch):
    while Lexer.is_digit(self.peek()):
      self.advance()

    if self.peek() == '.':
      self.advance()

    while Lexer.is_digit(self.peek()):
      self.advance()

    self.add_token(TokenType.NUMBER, float(self.source[self.start: self.current]))
  elif ch.isalpha():
    while self.peek() and self.peek().isalnum():
      self.advance()

    text = self.source[self.start: self.current]
    if TokenType.has_value(text):
      self.add_token(TokenType(text))
    else:
      self.add_token(TokenType.IDENTIFIER)
  else:
    raise InvalidSyntaxError('Unexpected token: ' + ch)
```

## 2.2 `lex` ë©”ì„œë“œ

ê·¸ë¦¬ê³  ì´ í† í° ì°¾ëŠ” ê²ƒì„ ì†ŒìŠ¤ì½”ë“œê°€ ëë‚ ë•Œê¹Œì§€ ë°˜ë³µí•´ì£¼ëŠ” `lex` ë©”ì„œë“œë¥¼ ë§Œë“¤ì–´ ë´…ì‹œë‹¤.

[rectapy/token/lexer.py](https://github.com/devonnuri/RectaPy/blob/95d855dd5c2a8607be0c32d4b70deeef4957fc66/rectapy/token/lexer.py#L16)
```python
def lex(self) -> List[Token]:
  while not self.is_end():
    self.start = self.current
    self.scan_token()

    self.tokens.append(Token(TokenType.EOF, ''))

    return self.tokens
```

ì´ê²ƒì´ ê°„ëµí•˜ê²Œ ì¤‘ìš” ë©”ì„œë“œë¥¼ ì†Œê°œí•œ ê²ƒì´ë©°, ìì„¸í•œ ì½”ë“œëŠ” [ì—¬ê¸°](https://github.com/devonnuri/RectaPy/blob/95d855dd5c2a8607be0c32d4b70deeef4957fc66/rectapy/token/lexer.py)ë¥¼ ì°¸ê³ í•˜ë©´ ë ê²ƒ ê°™ìŠµë‹ˆë‹¤.

# 3. âœ… í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„±

[test/lexer_test.py](https://github.com/devonnuri/RectaPy/blob/95d855dd5c2a8607be0c32d4b70deeef4957fc66/test/lexer_test.py)
```python
from rectapy import Lexer

if __name__ == '__main__':
    lexer = Lexer('10*2+3')

    tokens = lexer.lex()

    print('\n'.join(map(str, tokens)))
```

ì¼ë‹¨ ì†ŒìŠ¤ì½”ë“œë¥¼ ë„£ì€ ìƒíƒœì—ì„œ Lexer í´ë˜ìŠ¤ë¥¼ ë§Œë“¤ê³  `lex`í•œ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ë„ë¡ í–ˆìŠµë‹ˆë‹¤.

```
NUMBER 10 10.0
STAR * 
NUMBER 2 2.0
PLUS + 
NUMBER 3 3.0
EOF
```

ì„±ê³µì ì´êµ°ìš”! ì´ì œ ë‹¤ìŒì—ëŠ” ì•„ê¹Œ ë§í–ˆë“¯ì´ ASTë¼ê³  ë¶ˆë¦¬ëŠ” Parserë¥¼ ì§œì„œ Abstract Syntax Treeë¥¼ ë§Œë“¤ì–´ë³¼ê±°ì—ìš”!